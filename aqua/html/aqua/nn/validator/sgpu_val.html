<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>aqua.nn.validator.sgpu_val API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>aqua.nn.validator.sgpu_val</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import pdb
import sys
import time
import json
import math
import torch
import shutil
import pandas as pd
from barbar import Bar
from datetime import datetime
from torchsummary import summary
from sklearn.metrics import accuracy_score


class SGPU_Val:
    def __init__(self, workdir, net, vloader, max_epochs, criterion, eskip=1):
        &#34;&#34;&#34; Validates training checkpoints.

        Parameters
        ----------
        workdir: str
            Training directory having checkpoints
        net: Custom Network Instance
            Instance of pytorch custom network we will be 
            training
        vloader: Instance of Custom DataLoader
            Validation data loader instance
        max_epochs: int
            Maximum number of epochs for which the current
            network is trained.
        criterion: Loss instance
        eskip: int, optional
            Epoch skip interval between validations.
            Defaults to 1, performs validation for every
            epoch.
        
        Note
        ----
        1. Please use `CUDA_VISIBLE_DEVICES=1` to select 
           GPU. This code assumes to use GPU 0 always.
        2. The checkpoint files are assumed to be named
           `epoch_&lt;#&gt;.pth`.
        3. It also checks for training log file in working
           directory. It is assumed to be named trn_log.json
           
        &#34;&#34;&#34;
        self.workdir = workdir
        self.net = net
        self.vloader = vloader
        self.max_epochs = max_epochs
        self.eskip = eskip
        self.criterion = criterion

        # Load training log df from json file
        self._trn_df = self._load_trn_json()

    def _get_cuda_device(self, cuda_device_id):
        &#34;&#34;&#34; Sets NVIDIA device with id `cuda_device_id` to
        be used for training.

        Parameters
        ----------
        net: Custom Network Instance
            Instance of pytorch custom network we will be training
        cuda_device_id: int
            CUDA device ID
        &#34;&#34;&#34;
        if not torch.cuda.is_available():
            raise Exception(&#34;ERROR: Cuda is not found in this environment&#34;)

        num_cuda_devices = torch.cuda.device_count()
        cuda_devices = list(range(0,
                                  num_cuda_devices))  # cuda index start from 0

        if not (cuda_device_id &lt;= num_cuda_devices - 1):
            raise Exception(
                f&#34;ERROR: Cuda device {cuda_device_id} is not found.\n&#34;
                f&#34;ERROR: Found {num_cuda_devices}(&#34;
                f&#34;{cuda_devices}), Cuda devices&#34;)

        # If no errors load network onto cuda device
        print(&#34;INFO: Network sucessfully loaded into &#34;
              f&#34;CUDA device {cuda_device_id}&#34;)
        return f&#34;cuda:{cuda_device_id}&#34;

    def validate(self, log_path):
        &#34;&#34;&#34; Validation is performed here
        &#34;&#34;&#34;
        # Open log file to write
        log = open(log_path, &#34;w&#34;)
        now = datetime.now().strftime(&#34;%m/%d/%Y, %H:%M:%S&#34;)
        log.write(f&#39;{{&#34;mode&#34;: &#34;info&#34;, &#34;start_time&#34;:&#34;{now}&#34; }}&#39;)

        # Check if required checkpoint files are present
        epoch_lst = list(range(0, self.max_epochs, self.eskip))
        if not (self._are_epochs_valid(epoch_lst)):
            sys.exit()

        # Load net into GPU
        self.device = self._get_cuda_device(0)
        self.net.to(self.device)

        # Loop over each epoch under consideration
        for epoch in epoch_lst:
            # Load checkpoint weights to GPU
            epoch_path = f&#34;{self.workdir}/epoch_{epoch}.pth&#34;
            checkpoint = torch.load(epoch_path)
            self.net.load_state_dict(checkpoint[&#39;model_state_dict&#39;])

            # Evaluate
            self.net.eval()
            valloss, valaccu, valtt = self._get_val_loss_and_accuracy()

            # Training accuracy and loss for current epoch from training log
            trnaccu = self._trn_df[self._trn_df[&#39;epoch&#39;] ==
                                   epoch][&#39;acc&#39;].item()
            trnloss = self._trn_df[self._trn_df[&#39;epoch&#39;] ==
                                   epoch][&#39;loss&#39;].item()

            # Write validation log file
            valstr = (f&#39;{{&#34;mode&#34;: &#34;val&#34;, &#34;epoch&#34;:{epoch}, &#34;acc&#34;:{valaccu}, &#39;
                      f&#39;&#34;trnacc&#34;:{trnaccu}, &#34;loss&#34;:{valloss} }}&#39;)
            log.write(f&#34;\n{valstr}&#34;)
            log.flush()
            os.fsync(log.fileno())

        now = datetime.now().strftime(&#34;%m/%d/%Y, %H:%M:%S&#34;)
        log.write(f&#39;\n{{&#34;mode&#34;: &#34;info&#34;,  &#34;end_time&#34;:&#34;{now}&#34; }}&#39;)

    def _get_val_loss_and_accuracy(self):
        &#34;&#34;&#34; Returns validation accuracy and loss
        &#34;&#34;&#34;
        with torch.no_grad():
            valloss_lst = []
            valpred_lst = []
            valgt_lst = []
            valtt_lst = []
            for idx, data in enumerate(Bar(self.vloader)):
                valloss, valpred, valgt, valtt = self._eval_cur_iter(data)

                # Collect validation loss and prediction
                valloss_lst += [valloss]
                valpred_lst += valpred
                valtt_lst += [valtt]
                valgt_lst += valgt

            # Validation loss and prediction accuracy
            valgt_lst = [round(x) for x in valgt_lst]
            valpred_lst = [round(x) for x in valpred_lst]
            tot_valtt = round(sum(valtt_lst), 5)
            avg_valloss = round(sum(valloss_lst) / len(valloss_lst), 2)
            valaccu = round(accuracy_score(valgt_lst, valpred_lst), 2)

        return avg_valloss, valaccu, tot_valtt

    def _eval_cur_iter(self, data):
        &#34;&#34;&#34; Tests
        &#34;&#34;&#34;
        labels, inputs = (data[0].to(self.device, non_blocking=True),
                          data[1].to(self.device, non_blocking=True))
        labels = torch.reshape(labels.float(), (-1, 1))
        ilabels = labels.data.clone()
        ilabels = ilabels.to(&#34;cpu&#34;).numpy().flatten().tolist()

        st = time.time()
        outputs = self.net(inputs)
        et = time.time()
        ipred = outputs.data.clone()
        ipred = ipred.to(&#34;cpu&#34;).numpy().flatten().tolist()

        # Loss
        loss = self.criterion(outputs, labels)
        iloss = loss.data.clone()
        iloss = iloss.to(&#34;cpu&#34;).numpy().tolist()

        # Time taken
        tt = round(et - st, 5)

        return iloss, ipred, ilabels, tt

    def _are_epochs_valid(self, epoch_lst):
        &#34;&#34;&#34; Returns True if we can find all the eopocsh in
        the epoch list
        &#34;&#34;&#34;
        epoch_path_lst = [f&#34;{self.workdir}/epoch_{x}.pth&#34; for x in epoch_lst]
        for epoch_path in epoch_path_lst:
            if not os.path.isfile(epoch_path):
                return False

        return True

    def _load_trn_json(self):
        &#34;&#34;&#34; Load training log file as df
        &#34;&#34;&#34;
        # Loading training json file
        trn_log_path = f&#34;{self.workdir}/trn_log.json&#34;
        if not os.path.isfile(trn_log_path):
            raise Exception(f&#34;{trn_log_path} does not exist&#34;)
        with open(trn_log_path, &#34;r&#34;) as f:
            lines = f.readlines()

        # Creating dataframes for training and validation
        trn_dict_lst = []
        for cur_line in lines:
            cur_line_dict = json.loads(cur_line.rstrip())
            if cur_line_dict[&#39;mode&#39;] == &#34;train&#34;:
                trn_dict_lst += [cur_line_dict]

        # Creating dataframes from list of dictionaries
        trn_df = pd.DataFrame(trn_dict_lst)
        return trn_df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="aqua.nn.validator.sgpu_val.SGPU_Val"><code class="flex name class">
<span>class <span class="ident">SGPU_Val</span></span>
<span>(</span><span>workdir, net, vloader, max_epochs, criterion, eskip=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Validates training checkpoints.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>workdir</code></strong> :&ensp;<code>str</code></dt>
<dd>Training directory having checkpoints</dd>
<dt><strong><code>net</code></strong> :&ensp;<code>Custom Network Instance</code></dt>
<dd>Instance of pytorch custom network we will be
training</dd>
<dt><strong><code>vloader</code></strong> :&ensp;<code>Instance</code> of <code>Custom DataLoader</code></dt>
<dd>Validation data loader instance</dd>
<dt><strong><code>max_epochs</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum number of epochs for which the current
network is trained.</dd>
<dt><strong><code>criterion</code></strong> :&ensp;<code>Loss instance</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>eskip</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Epoch skip interval between validations.
Defaults to 1, performs validation for every
epoch.</dd>
</dl>
<h2 id="note">Note</h2>
<ol>
<li>Please use <code>CUDA_VISIBLE_DEVICES=1</code> to select
GPU. This code assumes to use GPU 0 always.</li>
<li>The checkpoint files are assumed to be named
<code>epoch_&lt;#&gt;.pth</code>.</li>
<li>It also checks for training log file in working
directory. It is assumed to be named trn_log.json</li>
</ol></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SGPU_Val:
    def __init__(self, workdir, net, vloader, max_epochs, criterion, eskip=1):
        &#34;&#34;&#34; Validates training checkpoints.

        Parameters
        ----------
        workdir: str
            Training directory having checkpoints
        net: Custom Network Instance
            Instance of pytorch custom network we will be 
            training
        vloader: Instance of Custom DataLoader
            Validation data loader instance
        max_epochs: int
            Maximum number of epochs for which the current
            network is trained.
        criterion: Loss instance
        eskip: int, optional
            Epoch skip interval between validations.
            Defaults to 1, performs validation for every
            epoch.
        
        Note
        ----
        1. Please use `CUDA_VISIBLE_DEVICES=1` to select 
           GPU. This code assumes to use GPU 0 always.
        2. The checkpoint files are assumed to be named
           `epoch_&lt;#&gt;.pth`.
        3. It also checks for training log file in working
           directory. It is assumed to be named trn_log.json
           
        &#34;&#34;&#34;
        self.workdir = workdir
        self.net = net
        self.vloader = vloader
        self.max_epochs = max_epochs
        self.eskip = eskip
        self.criterion = criterion

        # Load training log df from json file
        self._trn_df = self._load_trn_json()

    def _get_cuda_device(self, cuda_device_id):
        &#34;&#34;&#34; Sets NVIDIA device with id `cuda_device_id` to
        be used for training.

        Parameters
        ----------
        net: Custom Network Instance
            Instance of pytorch custom network we will be training
        cuda_device_id: int
            CUDA device ID
        &#34;&#34;&#34;
        if not torch.cuda.is_available():
            raise Exception(&#34;ERROR: Cuda is not found in this environment&#34;)

        num_cuda_devices = torch.cuda.device_count()
        cuda_devices = list(range(0,
                                  num_cuda_devices))  # cuda index start from 0

        if not (cuda_device_id &lt;= num_cuda_devices - 1):
            raise Exception(
                f&#34;ERROR: Cuda device {cuda_device_id} is not found.\n&#34;
                f&#34;ERROR: Found {num_cuda_devices}(&#34;
                f&#34;{cuda_devices}), Cuda devices&#34;)

        # If no errors load network onto cuda device
        print(&#34;INFO: Network sucessfully loaded into &#34;
              f&#34;CUDA device {cuda_device_id}&#34;)
        return f&#34;cuda:{cuda_device_id}&#34;

    def validate(self, log_path):
        &#34;&#34;&#34; Validation is performed here
        &#34;&#34;&#34;
        # Open log file to write
        log = open(log_path, &#34;w&#34;)
        now = datetime.now().strftime(&#34;%m/%d/%Y, %H:%M:%S&#34;)
        log.write(f&#39;{{&#34;mode&#34;: &#34;info&#34;, &#34;start_time&#34;:&#34;{now}&#34; }}&#39;)

        # Check if required checkpoint files are present
        epoch_lst = list(range(0, self.max_epochs, self.eskip))
        if not (self._are_epochs_valid(epoch_lst)):
            sys.exit()

        # Load net into GPU
        self.device = self._get_cuda_device(0)
        self.net.to(self.device)

        # Loop over each epoch under consideration
        for epoch in epoch_lst:
            # Load checkpoint weights to GPU
            epoch_path = f&#34;{self.workdir}/epoch_{epoch}.pth&#34;
            checkpoint = torch.load(epoch_path)
            self.net.load_state_dict(checkpoint[&#39;model_state_dict&#39;])

            # Evaluate
            self.net.eval()
            valloss, valaccu, valtt = self._get_val_loss_and_accuracy()

            # Training accuracy and loss for current epoch from training log
            trnaccu = self._trn_df[self._trn_df[&#39;epoch&#39;] ==
                                   epoch][&#39;acc&#39;].item()
            trnloss = self._trn_df[self._trn_df[&#39;epoch&#39;] ==
                                   epoch][&#39;loss&#39;].item()

            # Write validation log file
            valstr = (f&#39;{{&#34;mode&#34;: &#34;val&#34;, &#34;epoch&#34;:{epoch}, &#34;acc&#34;:{valaccu}, &#39;
                      f&#39;&#34;trnacc&#34;:{trnaccu}, &#34;loss&#34;:{valloss} }}&#39;)
            log.write(f&#34;\n{valstr}&#34;)
            log.flush()
            os.fsync(log.fileno())

        now = datetime.now().strftime(&#34;%m/%d/%Y, %H:%M:%S&#34;)
        log.write(f&#39;\n{{&#34;mode&#34;: &#34;info&#34;,  &#34;end_time&#34;:&#34;{now}&#34; }}&#39;)

    def _get_val_loss_and_accuracy(self):
        &#34;&#34;&#34; Returns validation accuracy and loss
        &#34;&#34;&#34;
        with torch.no_grad():
            valloss_lst = []
            valpred_lst = []
            valgt_lst = []
            valtt_lst = []
            for idx, data in enumerate(Bar(self.vloader)):
                valloss, valpred, valgt, valtt = self._eval_cur_iter(data)

                # Collect validation loss and prediction
                valloss_lst += [valloss]
                valpred_lst += valpred
                valtt_lst += [valtt]
                valgt_lst += valgt

            # Validation loss and prediction accuracy
            valgt_lst = [round(x) for x in valgt_lst]
            valpred_lst = [round(x) for x in valpred_lst]
            tot_valtt = round(sum(valtt_lst), 5)
            avg_valloss = round(sum(valloss_lst) / len(valloss_lst), 2)
            valaccu = round(accuracy_score(valgt_lst, valpred_lst), 2)

        return avg_valloss, valaccu, tot_valtt

    def _eval_cur_iter(self, data):
        &#34;&#34;&#34; Tests
        &#34;&#34;&#34;
        labels, inputs = (data[0].to(self.device, non_blocking=True),
                          data[1].to(self.device, non_blocking=True))
        labels = torch.reshape(labels.float(), (-1, 1))
        ilabels = labels.data.clone()
        ilabels = ilabels.to(&#34;cpu&#34;).numpy().flatten().tolist()

        st = time.time()
        outputs = self.net(inputs)
        et = time.time()
        ipred = outputs.data.clone()
        ipred = ipred.to(&#34;cpu&#34;).numpy().flatten().tolist()

        # Loss
        loss = self.criterion(outputs, labels)
        iloss = loss.data.clone()
        iloss = iloss.to(&#34;cpu&#34;).numpy().tolist()

        # Time taken
        tt = round(et - st, 5)

        return iloss, ipred, ilabels, tt

    def _are_epochs_valid(self, epoch_lst):
        &#34;&#34;&#34; Returns True if we can find all the eopocsh in
        the epoch list
        &#34;&#34;&#34;
        epoch_path_lst = [f&#34;{self.workdir}/epoch_{x}.pth&#34; for x in epoch_lst]
        for epoch_path in epoch_path_lst:
            if not os.path.isfile(epoch_path):
                return False

        return True

    def _load_trn_json(self):
        &#34;&#34;&#34; Load training log file as df
        &#34;&#34;&#34;
        # Loading training json file
        trn_log_path = f&#34;{self.workdir}/trn_log.json&#34;
        if not os.path.isfile(trn_log_path):
            raise Exception(f&#34;{trn_log_path} does not exist&#34;)
        with open(trn_log_path, &#34;r&#34;) as f:
            lines = f.readlines()

        # Creating dataframes for training and validation
        trn_dict_lst = []
        for cur_line in lines:
            cur_line_dict = json.loads(cur_line.rstrip())
            if cur_line_dict[&#39;mode&#39;] == &#34;train&#34;:
                trn_dict_lst += [cur_line_dict]

        # Creating dataframes from list of dictionaries
        trn_df = pd.DataFrame(trn_dict_lst)
        return trn_df</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="aqua.nn.validator.sgpu_val.SGPU_Val.validate"><code class="name flex">
<span>def <span class="ident">validate</span></span>(<span>self, log_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Validation is performed here</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate(self, log_path):
    &#34;&#34;&#34; Validation is performed here
    &#34;&#34;&#34;
    # Open log file to write
    log = open(log_path, &#34;w&#34;)
    now = datetime.now().strftime(&#34;%m/%d/%Y, %H:%M:%S&#34;)
    log.write(f&#39;{{&#34;mode&#34;: &#34;info&#34;, &#34;start_time&#34;:&#34;{now}&#34; }}&#39;)

    # Check if required checkpoint files are present
    epoch_lst = list(range(0, self.max_epochs, self.eskip))
    if not (self._are_epochs_valid(epoch_lst)):
        sys.exit()

    # Load net into GPU
    self.device = self._get_cuda_device(0)
    self.net.to(self.device)

    # Loop over each epoch under consideration
    for epoch in epoch_lst:
        # Load checkpoint weights to GPU
        epoch_path = f&#34;{self.workdir}/epoch_{epoch}.pth&#34;
        checkpoint = torch.load(epoch_path)
        self.net.load_state_dict(checkpoint[&#39;model_state_dict&#39;])

        # Evaluate
        self.net.eval()
        valloss, valaccu, valtt = self._get_val_loss_and_accuracy()

        # Training accuracy and loss for current epoch from training log
        trnaccu = self._trn_df[self._trn_df[&#39;epoch&#39;] ==
                               epoch][&#39;acc&#39;].item()
        trnloss = self._trn_df[self._trn_df[&#39;epoch&#39;] ==
                               epoch][&#39;loss&#39;].item()

        # Write validation log file
        valstr = (f&#39;{{&#34;mode&#34;: &#34;val&#34;, &#34;epoch&#34;:{epoch}, &#34;acc&#34;:{valaccu}, &#39;
                  f&#39;&#34;trnacc&#34;:{trnaccu}, &#34;loss&#34;:{valloss} }}&#39;)
        log.write(f&#34;\n{valstr}&#34;)
        log.flush()
        os.fsync(log.fileno())

    now = datetime.now().strftime(&#34;%m/%d/%Y, %H:%M:%S&#34;)
    log.write(f&#39;\n{{&#34;mode&#34;: &#34;info&#34;,  &#34;end_time&#34;:&#34;{now}&#34; }}&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="aqua.nn.validator" href="index.html">aqua.nn.validator</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="aqua.nn.validator.sgpu_val.SGPU_Val" href="#aqua.nn.validator.sgpu_val.SGPU_Val">SGPU_Val</a></code></h4>
<ul class="">
<li><code><a title="aqua.nn.validator.sgpu_val.SGPU_Val.validate" href="#aqua.nn.validator.sgpu_val.SGPU_Val.validate">validate</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>