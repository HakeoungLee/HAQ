<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>aqua.data_tools.aolme.activity_labels.activity_labels_new API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>aqua.data_tools.aolme.activity_labels.activity_labels_new</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import sys
import pdb
import aqua
import math
import datetime
import numpy as np
import pandas as pd
import pretty_errors
import skvideo.io as skvio
from aqua.data_tools.aolme.activity_labels.standardize import Standardize
from aqua.data_tools.aolme.activity_labels.process import Process
from aqua.data_tools.aolme.activity_labels.summarize import Summarize
from aqua.data_tools.aolme.activity_labels.visualize import Visualize

class AOLMEActivityLabels:
    def __init__(self, rdir, labels_fname):
        &#34;&#34;&#34; Methods to (1). Standardize, (2). Analyze
        and (3). Process activity labels.

        Parameters
        ----------
        rdir: str
            Directory path having activity labels.
        labels_fname: str
            Name of the file that has activity labels.
        &#34;&#34;&#34;
        self._rdir = rdir
        self._fname = labels_fname

    def create_labeled_videos(self, names_csv, activity):
        &#34;&#34;&#34;
        The following method overlays labeles on video.

        Assumptions
        -----------
        1. The videos are present in the same directory as csv file
           containing the labels.

        Parameters
        ----------
        names_csv: str
            Path to csv file having numeric names and pseudonyms
        activity: str
            Activity that is being processed
        &#34;&#34;&#34;
        # Loading data from csv files to dataframes
        df = pd.read_csv(f&#34;{self._rdir}/{self._fname}&#34;)
        tydf = df[df[&#39;activity&#39;] == activity].copy()
        
        # Loading dataframe that contains pseudonyms
        ndf = pd.read_csv(f&#34;{names_csv}&#34;)
        
        # Initializing visualization instance
        viz = Visualize(self._rdir, tydf)
        viz.to_video_ffmpeg(names_df = ndf)



    def get_person_codes(self, ndf, row, person_code, person_code_type):
        &#34;&#34;&#34; Returns person information.
        &#34;&#34;&#34;
        
        if person_code_type == &#39;numeric_code&#39;:
            numeric_code = row[person_code]
            pseudonym = ndf[ndf[person_code_type] == numeric_code][&#39;pseudonym&#39;].item()
            student_code = ndf[ndf[person_code_type] == numeric_code][&#39;student_code&#39;].item()
            
        elif person_code_type == &#39;student_code&#39;:
            student_code = row[person_code]
            pseudonym = ndf[ndf[person_code_type] == student_code][&#39;pseudonym&#39;].item()
            numeric_code = ndf[ndf[person_code_type] == student_code][&#39;numeric_code&#39;].item()
                        
        elif person_code_type == &#39;pseudonym&#39;:
            pseudonym = row[person_code]
            numeric_code = ndf[ndf[person_code_type] == pseudonym][&#39;numeric_code&#39;].item()
            student_code = ndf[ndf[person_code_type] == pseudonym][&#39;student_code&#39;].item()
            
        else:
            print(f&#34;Does not support {person_code_type}&#34;)

        
        return numeric_code, pseudonym, student_code

    def create_xlsx(self, names_csv, out_xlsx, activity, person_code, person_code_type):
        &#34;&#34;&#34;
        The following code parses ground truth csv file to xlsx sheets.
        This is done to provide easy access to education researchers.

        NOTE
        ----
        This method assumes the existance of `properties_session.csv` file.
        This file contains information related every video in the session.
        

        Parameters
        ----------
        names_csv: str
            Path to csv file having numeric names and pseudonyms
        out_xlsx: str
            Path to output xlsx file
        activity: str
            Activity that is being processed
        person_code: str
            Column name having student identification
        person_code_type: str
            Type of student identification used, {numeric_code, student_code, pseudonym}
        &#34;&#34;&#34;
        # Session properties
        sprops = pd.read_csv(f&#34;{self._rdir}/properties_session.csv&#34;)
        sdur_sec = sprops[sprops[&#39;name&#39;] == &#39;total&#39;][&#39;dur&#39;].item()

        # Loading dataframe that contains pseudonyms
        ndf = pd.read_csv(f&#34;{names_csv}&#34;)

        # Load dataframe that has typing instances
        df = pd.read_csv(f&#34;{self._rdir}/{self._fname}&#34;)
        tydf = df[df[&#39;activity&#39;] == activity].copy()
        persons = tydf[person_code].unique()

        # Loop over all typing instances and collect information
        hrlist = [] # Human readable
        for ridx, row in tydf.iterrows():

            # Information of tydf
            name = row[&#39;name&#39;]
            stime = math.ceil(row[&#39;f0&#39;]/row[&#39;FPS&#39;])
            stime_str = str(datetime.timedelta(seconds=stime))
            etime = math.floor(stime + (row[&#39;f&#39;]/row[&#39;FPS&#39;]))
            etime_str = str(datetime.timedelta(seconds=etime))
            dur_sec = etime - stime
            dur_min = round(dur_sec/60.0, 2)
            dur_str = str(datetime.timedelta(seconds=dur_sec))
            w0 = math.floor(row[&#39;w0&#39;])
            h0 = math.floor(row[&#39;h0&#39;])
            w = math.floor(row[&#39;w&#39;])
            h = math.floor(row[&#39;h&#39;])
            
            # Getting person name information
            numeric_code, pseudonym, student_code = self.get_person_codes(ndf, row, person_code, person_code_type)

            # Creating list
            hrlist += [[name, numeric_code, pseudonym, student_code,
                        stime_str, etime_str, dur_str,
                        w0, h0, w, h]]




            
        
        # Output dataframe
        try:
            odf = pd.DataFrame(hrlist, columns=[&#39;Video name&#39;, &#39;Numeric code&#39;, &#39;Pseudonym&#39;, &#39;Student code&#39;,
                                            &#39;Start time&#39;, &#39;End time&#39;, &#39;Duration&#39;,
                                            &#39;w0&#39;, &#39;h0&#39;, &#39;w&#39;, &#39;h&#39;])
        except:
            import pdb; pdb.set_trace()

        # Export to excel
        
        print(f&#34;INFO: Writing {out_xlsx}&#34;)
        writer = pd.ExcelWriter(out_xlsx, engine=&#39;xlsxwriter&#39;)
        odf.to_excel(writer, sheet_name=&#34;Human readable&#34;, index=False)

        # Adding pseudonym, numeric_code, student_code to tydf
        tydf[&#39;pseudonym&#39;] = [row[2] for row in hrlist]
        tydf[&#39;numeric_code&#39;] = [row[1] for row in hrlist]
        tydf[&#39;student_code&#39;] = [row[3] for row in hrlist]
        tydf.to_excel(writer, sheet_name=&#34;Machine readable&#34;, index=False)
        writer.save()
        

    def save_summary_to_json(self):
        &#34;&#34;&#34; Method that summarizes activity labels to a text
        file. The file is saved as `summary.json` in the root
        directory.
        &#34;&#34;&#34;
        flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

        # Create a data frame from all the activity labels
        df = self._load_all_activity_labels(flist)

        # Add time column to data frame
        df = self._add_time(df)

        # Creating sumarize instance
        summary = Summarize(df)

        # Sumamry file path
        opth = f&#34;{self._rdir}/summary.json&#34;

        # Summarize to text file
        summary.to_json(opth)

    def hist_of_activity_labels(self, title):
        &#34;&#34;&#34; The following method saves histograms of
        width, height and duration of bounding boxes.
        &#34;&#34;&#34;
        flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

        # Create a data frame from all the activity labels
        df = self._load_all_activity_labels(flist)

        # Add time duration in seconds to data frame
        df = self._add_time(df)

        # Write code from here
        pdb.set_trace()

    def standardize_activity_labels(self, fr=30, overwrite=False):
        &#34;&#34;&#34; Standardizes activity labels.

        Parameters
        ----------
        fr: int, optional
            Required frame rate.
        overwrite: bool, optional
            Overwrites. Defaults to False
        &#34;&#34;&#34;
        # Standardizing activity labels
        std = Standardize(self._rdir, self._fname, fr, overwrite)
        std.create_activity_labels_at_fr()

    def standardize_videos(self, vdb_path, fr=30, overwrite=False):
        &#34;&#34;&#34; Standardizes video frame rate in videos.

        Parameters
        ----------
        vdb_path: str
            Video data base path having download link to videos.
        fr: int, optional
            Required frame rate.
        overwrite: bool, optional
            Overwrites. Defaults to False
        &#34;&#34;&#34;
        # Standardizing videos
        std = Standardize(self._rdir, self._fname, fr, overwrite)
        std.transcode_videos_at_fr(vdb_path)

    def create_spatiotemporal_trims(self,
                                    odir,
                                    trims_per_instance=1,
                                    dur=3,
                                    overwrite=False):
        &#34;&#34;&#34; Creates one spatiotemporal trim per one instance of activity
        label.

        Parameters
        ----------
        odir: str
            Path of direcotry to store trims.
        trims_per_instance: int,
            Number of trims to be extracted from one instance of
            activity label. -1 implies that we trim completely.
        dur: int, optional
            Duration of each trim in seconds. Defaults to 3.
        overwrite: bool, optional
            Overwrites. Defaults to False
        &#34;&#34;&#34;
        flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

        # Create a data frame from all the activity labels
        df = self._load_all_activity_labels(flist)

        # Add time column to data frame
        df = self._add_time(df)

        proc = Process(self._rdir, self._fname)
        if trims_per_instance == 1:
            proc.one_trim_per_instance(odir, dur, overwrite)
        elif trims_per_instance == -1:
            proc.trim_instances(odir, overwrite)
        else:
            raise Exception(&#34;Invalid trims per instance, &#34;
                            f&#34;{trims_per_instance}&#34;)

    def _load_all_activity_labels(self, flist):
        &#34;&#34;&#34; Loads all activity labels present under rood directory inot
        one dataframe.

        Parameters
        ----------
        flist: list of str
            List of csv file paths having activity labels.
        &#34;&#34;&#34;
        dflst = []
        for f in flist:
            dflst += [pd.read_csv(f)]

        return pd.concat(dflst, ignore_index=True)

    def _add_time(self, df):
        &#34;&#34;&#34; Adds time column to data frame
        
        Parameters
        ----------
        df: DataFrame
            DataFrame having activity label instances
        &#34;&#34;&#34;
        fps = df[&#39;FPS&#39;].to_numpy()
        f = df[&#39;f&#39;].to_numpy()
        t = np.round(f / fps, 2)

        df[&#39;t&#39;] = t

        return df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels"><code class="flex name class">
<span>class <span class="ident">AOLMEActivityLabels</span></span>
<span>(</span><span>rdir, labels_fname)</span>
</code></dt>
<dd>
<div class="desc"><p>Methods to (1). Standardize, (2). Analyze
and (3). Process activity labels.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>rdir</code></strong> :&ensp;<code>str</code></dt>
<dd>Directory path having activity labels.</dd>
<dt><strong><code>labels_fname</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the file that has activity labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AOLMEActivityLabels:
    def __init__(self, rdir, labels_fname):
        &#34;&#34;&#34; Methods to (1). Standardize, (2). Analyze
        and (3). Process activity labels.

        Parameters
        ----------
        rdir: str
            Directory path having activity labels.
        labels_fname: str
            Name of the file that has activity labels.
        &#34;&#34;&#34;
        self._rdir = rdir
        self._fname = labels_fname

    def create_labeled_videos(self, names_csv, activity):
        &#34;&#34;&#34;
        The following method overlays labeles on video.

        Assumptions
        -----------
        1. The videos are present in the same directory as csv file
           containing the labels.

        Parameters
        ----------
        names_csv: str
            Path to csv file having numeric names and pseudonyms
        activity: str
            Activity that is being processed
        &#34;&#34;&#34;
        # Loading data from csv files to dataframes
        df = pd.read_csv(f&#34;{self._rdir}/{self._fname}&#34;)
        tydf = df[df[&#39;activity&#39;] == activity].copy()
        
        # Loading dataframe that contains pseudonyms
        ndf = pd.read_csv(f&#34;{names_csv}&#34;)
        
        # Initializing visualization instance
        viz = Visualize(self._rdir, tydf)
        viz.to_video_ffmpeg(names_df = ndf)



    def get_person_codes(self, ndf, row, person_code, person_code_type):
        &#34;&#34;&#34; Returns person information.
        &#34;&#34;&#34;
        
        if person_code_type == &#39;numeric_code&#39;:
            numeric_code = row[person_code]
            pseudonym = ndf[ndf[person_code_type] == numeric_code][&#39;pseudonym&#39;].item()
            student_code = ndf[ndf[person_code_type] == numeric_code][&#39;student_code&#39;].item()
            
        elif person_code_type == &#39;student_code&#39;:
            student_code = row[person_code]
            pseudonym = ndf[ndf[person_code_type] == student_code][&#39;pseudonym&#39;].item()
            numeric_code = ndf[ndf[person_code_type] == student_code][&#39;numeric_code&#39;].item()
                        
        elif person_code_type == &#39;pseudonym&#39;:
            pseudonym = row[person_code]
            numeric_code = ndf[ndf[person_code_type] == pseudonym][&#39;numeric_code&#39;].item()
            student_code = ndf[ndf[person_code_type] == pseudonym][&#39;student_code&#39;].item()
            
        else:
            print(f&#34;Does not support {person_code_type}&#34;)

        
        return numeric_code, pseudonym, student_code

    def create_xlsx(self, names_csv, out_xlsx, activity, person_code, person_code_type):
        &#34;&#34;&#34;
        The following code parses ground truth csv file to xlsx sheets.
        This is done to provide easy access to education researchers.

        NOTE
        ----
        This method assumes the existance of `properties_session.csv` file.
        This file contains information related every video in the session.
        

        Parameters
        ----------
        names_csv: str
            Path to csv file having numeric names and pseudonyms
        out_xlsx: str
            Path to output xlsx file
        activity: str
            Activity that is being processed
        person_code: str
            Column name having student identification
        person_code_type: str
            Type of student identification used, {numeric_code, student_code, pseudonym}
        &#34;&#34;&#34;
        # Session properties
        sprops = pd.read_csv(f&#34;{self._rdir}/properties_session.csv&#34;)
        sdur_sec = sprops[sprops[&#39;name&#39;] == &#39;total&#39;][&#39;dur&#39;].item()

        # Loading dataframe that contains pseudonyms
        ndf = pd.read_csv(f&#34;{names_csv}&#34;)

        # Load dataframe that has typing instances
        df = pd.read_csv(f&#34;{self._rdir}/{self._fname}&#34;)
        tydf = df[df[&#39;activity&#39;] == activity].copy()
        persons = tydf[person_code].unique()

        # Loop over all typing instances and collect information
        hrlist = [] # Human readable
        for ridx, row in tydf.iterrows():

            # Information of tydf
            name = row[&#39;name&#39;]
            stime = math.ceil(row[&#39;f0&#39;]/row[&#39;FPS&#39;])
            stime_str = str(datetime.timedelta(seconds=stime))
            etime = math.floor(stime + (row[&#39;f&#39;]/row[&#39;FPS&#39;]))
            etime_str = str(datetime.timedelta(seconds=etime))
            dur_sec = etime - stime
            dur_min = round(dur_sec/60.0, 2)
            dur_str = str(datetime.timedelta(seconds=dur_sec))
            w0 = math.floor(row[&#39;w0&#39;])
            h0 = math.floor(row[&#39;h0&#39;])
            w = math.floor(row[&#39;w&#39;])
            h = math.floor(row[&#39;h&#39;])
            
            # Getting person name information
            numeric_code, pseudonym, student_code = self.get_person_codes(ndf, row, person_code, person_code_type)

            # Creating list
            hrlist += [[name, numeric_code, pseudonym, student_code,
                        stime_str, etime_str, dur_str,
                        w0, h0, w, h]]




            
        
        # Output dataframe
        try:
            odf = pd.DataFrame(hrlist, columns=[&#39;Video name&#39;, &#39;Numeric code&#39;, &#39;Pseudonym&#39;, &#39;Student code&#39;,
                                            &#39;Start time&#39;, &#39;End time&#39;, &#39;Duration&#39;,
                                            &#39;w0&#39;, &#39;h0&#39;, &#39;w&#39;, &#39;h&#39;])
        except:
            import pdb; pdb.set_trace()

        # Export to excel
        
        print(f&#34;INFO: Writing {out_xlsx}&#34;)
        writer = pd.ExcelWriter(out_xlsx, engine=&#39;xlsxwriter&#39;)
        odf.to_excel(writer, sheet_name=&#34;Human readable&#34;, index=False)

        # Adding pseudonym, numeric_code, student_code to tydf
        tydf[&#39;pseudonym&#39;] = [row[2] for row in hrlist]
        tydf[&#39;numeric_code&#39;] = [row[1] for row in hrlist]
        tydf[&#39;student_code&#39;] = [row[3] for row in hrlist]
        tydf.to_excel(writer, sheet_name=&#34;Machine readable&#34;, index=False)
        writer.save()
        

    def save_summary_to_json(self):
        &#34;&#34;&#34; Method that summarizes activity labels to a text
        file. The file is saved as `summary.json` in the root
        directory.
        &#34;&#34;&#34;
        flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

        # Create a data frame from all the activity labels
        df = self._load_all_activity_labels(flist)

        # Add time column to data frame
        df = self._add_time(df)

        # Creating sumarize instance
        summary = Summarize(df)

        # Sumamry file path
        opth = f&#34;{self._rdir}/summary.json&#34;

        # Summarize to text file
        summary.to_json(opth)

    def hist_of_activity_labels(self, title):
        &#34;&#34;&#34; The following method saves histograms of
        width, height and duration of bounding boxes.
        &#34;&#34;&#34;
        flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

        # Create a data frame from all the activity labels
        df = self._load_all_activity_labels(flist)

        # Add time duration in seconds to data frame
        df = self._add_time(df)

        # Write code from here
        pdb.set_trace()

    def standardize_activity_labels(self, fr=30, overwrite=False):
        &#34;&#34;&#34; Standardizes activity labels.

        Parameters
        ----------
        fr: int, optional
            Required frame rate.
        overwrite: bool, optional
            Overwrites. Defaults to False
        &#34;&#34;&#34;
        # Standardizing activity labels
        std = Standardize(self._rdir, self._fname, fr, overwrite)
        std.create_activity_labels_at_fr()

    def standardize_videos(self, vdb_path, fr=30, overwrite=False):
        &#34;&#34;&#34; Standardizes video frame rate in videos.

        Parameters
        ----------
        vdb_path: str
            Video data base path having download link to videos.
        fr: int, optional
            Required frame rate.
        overwrite: bool, optional
            Overwrites. Defaults to False
        &#34;&#34;&#34;
        # Standardizing videos
        std = Standardize(self._rdir, self._fname, fr, overwrite)
        std.transcode_videos_at_fr(vdb_path)

    def create_spatiotemporal_trims(self,
                                    odir,
                                    trims_per_instance=1,
                                    dur=3,
                                    overwrite=False):
        &#34;&#34;&#34; Creates one spatiotemporal trim per one instance of activity
        label.

        Parameters
        ----------
        odir: str
            Path of direcotry to store trims.
        trims_per_instance: int,
            Number of trims to be extracted from one instance of
            activity label. -1 implies that we trim completely.
        dur: int, optional
            Duration of each trim in seconds. Defaults to 3.
        overwrite: bool, optional
            Overwrites. Defaults to False
        &#34;&#34;&#34;
        flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

        # Create a data frame from all the activity labels
        df = self._load_all_activity_labels(flist)

        # Add time column to data frame
        df = self._add_time(df)

        proc = Process(self._rdir, self._fname)
        if trims_per_instance == 1:
            proc.one_trim_per_instance(odir, dur, overwrite)
        elif trims_per_instance == -1:
            proc.trim_instances(odir, overwrite)
        else:
            raise Exception(&#34;Invalid trims per instance, &#34;
                            f&#34;{trims_per_instance}&#34;)

    def _load_all_activity_labels(self, flist):
        &#34;&#34;&#34; Loads all activity labels present under rood directory inot
        one dataframe.

        Parameters
        ----------
        flist: list of str
            List of csv file paths having activity labels.
        &#34;&#34;&#34;
        dflst = []
        for f in flist:
            dflst += [pd.read_csv(f)]

        return pd.concat(dflst, ignore_index=True)

    def _add_time(self, df):
        &#34;&#34;&#34; Adds time column to data frame
        
        Parameters
        ----------
        df: DataFrame
            DataFrame having activity label instances
        &#34;&#34;&#34;
        fps = df[&#39;FPS&#39;].to_numpy()
        f = df[&#39;f&#39;].to_numpy()
        t = np.round(f / fps, 2)

        df[&#39;t&#39;] = t

        return df</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_labeled_videos"><code class="name flex">
<span>def <span class="ident">create_labeled_videos</span></span>(<span>self, names_csv, activity)</span>
</code></dt>
<dd>
<div class="desc"><p>The following method overlays labeles on video.</p>
<h2 id="assumptions">Assumptions</h2>
<ol>
<li>The videos are present in the same directory as csv file
containing the labels.</li>
</ol>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>names_csv</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to csv file having numeric names and pseudonyms</dd>
<dt><strong><code>activity</code></strong> :&ensp;<code>str</code></dt>
<dd>Activity that is being processed</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_labeled_videos(self, names_csv, activity):
    &#34;&#34;&#34;
    The following method overlays labeles on video.

    Assumptions
    -----------
    1. The videos are present in the same directory as csv file
       containing the labels.

    Parameters
    ----------
    names_csv: str
        Path to csv file having numeric names and pseudonyms
    activity: str
        Activity that is being processed
    &#34;&#34;&#34;
    # Loading data from csv files to dataframes
    df = pd.read_csv(f&#34;{self._rdir}/{self._fname}&#34;)
    tydf = df[df[&#39;activity&#39;] == activity].copy()
    
    # Loading dataframe that contains pseudonyms
    ndf = pd.read_csv(f&#34;{names_csv}&#34;)
    
    # Initializing visualization instance
    viz = Visualize(self._rdir, tydf)
    viz.to_video_ffmpeg(names_df = ndf)</code></pre>
</details>
</dd>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_spatiotemporal_trims"><code class="name flex">
<span>def <span class="ident">create_spatiotemporal_trims</span></span>(<span>self, odir, trims_per_instance=1, dur=3, overwrite=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates one spatiotemporal trim per one instance of activity
label.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>odir</code></strong> :&ensp;<code>str</code></dt>
<dd>Path of direcotry to store trims.</dd>
<dt><strong><code>trims_per_instance</code></strong> :&ensp;<code>int,</code></dt>
<dd>Number of trims to be extracted from one instance of
activity label. -1 implies that we trim completely.</dd>
<dt><strong><code>dur</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Duration of each trim in seconds. Defaults to 3.</dd>
<dt><strong><code>overwrite</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Overwrites. Defaults to False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_spatiotemporal_trims(self,
                                odir,
                                trims_per_instance=1,
                                dur=3,
                                overwrite=False):
    &#34;&#34;&#34; Creates one spatiotemporal trim per one instance of activity
    label.

    Parameters
    ----------
    odir: str
        Path of direcotry to store trims.
    trims_per_instance: int,
        Number of trims to be extracted from one instance of
        activity label. -1 implies that we trim completely.
    dur: int, optional
        Duration of each trim in seconds. Defaults to 3.
    overwrite: bool, optional
        Overwrites. Defaults to False
    &#34;&#34;&#34;
    flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

    # Create a data frame from all the activity labels
    df = self._load_all_activity_labels(flist)

    # Add time column to data frame
    df = self._add_time(df)

    proc = Process(self._rdir, self._fname)
    if trims_per_instance == 1:
        proc.one_trim_per_instance(odir, dur, overwrite)
    elif trims_per_instance == -1:
        proc.trim_instances(odir, overwrite)
    else:
        raise Exception(&#34;Invalid trims per instance, &#34;
                        f&#34;{trims_per_instance}&#34;)</code></pre>
</details>
</dd>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_xlsx"><code class="name flex">
<span>def <span class="ident">create_xlsx</span></span>(<span>self, names_csv, out_xlsx, activity, person_code, person_code_type)</span>
</code></dt>
<dd>
<div class="desc"><p>The following code parses ground truth csv file to xlsx sheets.
This is done to provide easy access to education researchers.</p>
<h2 id="note">Note</h2>
<p>This method assumes the existance of <code>properties_session.csv</code> file.
This file contains information related every video in the session.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>names_csv</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to csv file having numeric names and pseudonyms</dd>
<dt><strong><code>out_xlsx</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to output xlsx file</dd>
<dt><strong><code>activity</code></strong> :&ensp;<code>str</code></dt>
<dd>Activity that is being processed</dd>
<dt><strong><code>person_code</code></strong> :&ensp;<code>str</code></dt>
<dd>Column name having student identification</dd>
<dt><strong><code>person_code_type</code></strong> :&ensp;<code>str</code></dt>
<dd>Type of student identification used, {numeric_code, student_code, pseudonym}</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_xlsx(self, names_csv, out_xlsx, activity, person_code, person_code_type):
    &#34;&#34;&#34;
    The following code parses ground truth csv file to xlsx sheets.
    This is done to provide easy access to education researchers.

    NOTE
    ----
    This method assumes the existance of `properties_session.csv` file.
    This file contains information related every video in the session.
    

    Parameters
    ----------
    names_csv: str
        Path to csv file having numeric names and pseudonyms
    out_xlsx: str
        Path to output xlsx file
    activity: str
        Activity that is being processed
    person_code: str
        Column name having student identification
    person_code_type: str
        Type of student identification used, {numeric_code, student_code, pseudonym}
    &#34;&#34;&#34;
    # Session properties
    sprops = pd.read_csv(f&#34;{self._rdir}/properties_session.csv&#34;)
    sdur_sec = sprops[sprops[&#39;name&#39;] == &#39;total&#39;][&#39;dur&#39;].item()

    # Loading dataframe that contains pseudonyms
    ndf = pd.read_csv(f&#34;{names_csv}&#34;)

    # Load dataframe that has typing instances
    df = pd.read_csv(f&#34;{self._rdir}/{self._fname}&#34;)
    tydf = df[df[&#39;activity&#39;] == activity].copy()
    persons = tydf[person_code].unique()

    # Loop over all typing instances and collect information
    hrlist = [] # Human readable
    for ridx, row in tydf.iterrows():

        # Information of tydf
        name = row[&#39;name&#39;]
        stime = math.ceil(row[&#39;f0&#39;]/row[&#39;FPS&#39;])
        stime_str = str(datetime.timedelta(seconds=stime))
        etime = math.floor(stime + (row[&#39;f&#39;]/row[&#39;FPS&#39;]))
        etime_str = str(datetime.timedelta(seconds=etime))
        dur_sec = etime - stime
        dur_min = round(dur_sec/60.0, 2)
        dur_str = str(datetime.timedelta(seconds=dur_sec))
        w0 = math.floor(row[&#39;w0&#39;])
        h0 = math.floor(row[&#39;h0&#39;])
        w = math.floor(row[&#39;w&#39;])
        h = math.floor(row[&#39;h&#39;])
        
        # Getting person name information
        numeric_code, pseudonym, student_code = self.get_person_codes(ndf, row, person_code, person_code_type)

        # Creating list
        hrlist += [[name, numeric_code, pseudonym, student_code,
                    stime_str, etime_str, dur_str,
                    w0, h0, w, h]]




        
    
    # Output dataframe
    try:
        odf = pd.DataFrame(hrlist, columns=[&#39;Video name&#39;, &#39;Numeric code&#39;, &#39;Pseudonym&#39;, &#39;Student code&#39;,
                                        &#39;Start time&#39;, &#39;End time&#39;, &#39;Duration&#39;,
                                        &#39;w0&#39;, &#39;h0&#39;, &#39;w&#39;, &#39;h&#39;])
    except:
        import pdb; pdb.set_trace()

    # Export to excel
    
    print(f&#34;INFO: Writing {out_xlsx}&#34;)
    writer = pd.ExcelWriter(out_xlsx, engine=&#39;xlsxwriter&#39;)
    odf.to_excel(writer, sheet_name=&#34;Human readable&#34;, index=False)

    # Adding pseudonym, numeric_code, student_code to tydf
    tydf[&#39;pseudonym&#39;] = [row[2] for row in hrlist]
    tydf[&#39;numeric_code&#39;] = [row[1] for row in hrlist]
    tydf[&#39;student_code&#39;] = [row[3] for row in hrlist]
    tydf.to_excel(writer, sheet_name=&#34;Machine readable&#34;, index=False)
    writer.save()</code></pre>
</details>
</dd>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.get_person_codes"><code class="name flex">
<span>def <span class="ident">get_person_codes</span></span>(<span>self, ndf, row, person_code, person_code_type)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns person information.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_person_codes(self, ndf, row, person_code, person_code_type):
    &#34;&#34;&#34; Returns person information.
    &#34;&#34;&#34;
    
    if person_code_type == &#39;numeric_code&#39;:
        numeric_code = row[person_code]
        pseudonym = ndf[ndf[person_code_type] == numeric_code][&#39;pseudonym&#39;].item()
        student_code = ndf[ndf[person_code_type] == numeric_code][&#39;student_code&#39;].item()
        
    elif person_code_type == &#39;student_code&#39;:
        student_code = row[person_code]
        pseudonym = ndf[ndf[person_code_type] == student_code][&#39;pseudonym&#39;].item()
        numeric_code = ndf[ndf[person_code_type] == student_code][&#39;numeric_code&#39;].item()
                    
    elif person_code_type == &#39;pseudonym&#39;:
        pseudonym = row[person_code]
        numeric_code = ndf[ndf[person_code_type] == pseudonym][&#39;numeric_code&#39;].item()
        student_code = ndf[ndf[person_code_type] == pseudonym][&#39;student_code&#39;].item()
        
    else:
        print(f&#34;Does not support {person_code_type}&#34;)

    
    return numeric_code, pseudonym, student_code</code></pre>
</details>
</dd>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.hist_of_activity_labels"><code class="name flex">
<span>def <span class="ident">hist_of_activity_labels</span></span>(<span>self, title)</span>
</code></dt>
<dd>
<div class="desc"><p>The following method saves histograms of
width, height and duration of bounding boxes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hist_of_activity_labels(self, title):
    &#34;&#34;&#34; The following method saves histograms of
    width, height and duration of bounding boxes.
    &#34;&#34;&#34;
    flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

    # Create a data frame from all the activity labels
    df = self._load_all_activity_labels(flist)

    # Add time duration in seconds to data frame
    df = self._add_time(df)

    # Write code from here
    pdb.set_trace()</code></pre>
</details>
</dd>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.save_summary_to_json"><code class="name flex">
<span>def <span class="ident">save_summary_to_json</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method that summarizes activity labels to a text
file. The file is saved as <code>summary.json</code> in the root
directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_summary_to_json(self):
    &#34;&#34;&#34; Method that summarizes activity labels to a text
    file. The file is saved as `summary.json` in the root
    directory.
    &#34;&#34;&#34;
    flist = aqua.get_file_paths_with_kws(self._rdir, [self._fname])

    # Create a data frame from all the activity labels
    df = self._load_all_activity_labels(flist)

    # Add time column to data frame
    df = self._add_time(df)

    # Creating sumarize instance
    summary = Summarize(df)

    # Sumamry file path
    opth = f&#34;{self._rdir}/summary.json&#34;

    # Summarize to text file
    summary.to_json(opth)</code></pre>
</details>
</dd>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.standardize_activity_labels"><code class="name flex">
<span>def <span class="ident">standardize_activity_labels</span></span>(<span>self, fr=30, overwrite=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Standardizes activity labels.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fr</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Required frame rate.</dd>
<dt><strong><code>overwrite</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Overwrites. Defaults to False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def standardize_activity_labels(self, fr=30, overwrite=False):
    &#34;&#34;&#34; Standardizes activity labels.

    Parameters
    ----------
    fr: int, optional
        Required frame rate.
    overwrite: bool, optional
        Overwrites. Defaults to False
    &#34;&#34;&#34;
    # Standardizing activity labels
    std = Standardize(self._rdir, self._fname, fr, overwrite)
    std.create_activity_labels_at_fr()</code></pre>
</details>
</dd>
<dt id="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.standardize_videos"><code class="name flex">
<span>def <span class="ident">standardize_videos</span></span>(<span>self, vdb_path, fr=30, overwrite=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Standardizes video frame rate in videos.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>vdb_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Video data base path having download link to videos.</dd>
<dt><strong><code>fr</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Required frame rate.</dd>
<dt><strong><code>overwrite</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Overwrites. Defaults to False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def standardize_videos(self, vdb_path, fr=30, overwrite=False):
    &#34;&#34;&#34; Standardizes video frame rate in videos.

    Parameters
    ----------
    vdb_path: str
        Video data base path having download link to videos.
    fr: int, optional
        Required frame rate.
    overwrite: bool, optional
        Overwrites. Defaults to False
    &#34;&#34;&#34;
    # Standardizing videos
    std = Standardize(self._rdir, self._fname, fr, overwrite)
    std.transcode_videos_at_fr(vdb_path)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="aqua.data_tools.aolme.activity_labels" href="index.html">aqua.data_tools.aolme.activity_labels</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels">AOLMEActivityLabels</a></code></h4>
<ul class="">
<li><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_labeled_videos" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_labeled_videos">create_labeled_videos</a></code></li>
<li><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_spatiotemporal_trims" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_spatiotemporal_trims">create_spatiotemporal_trims</a></code></li>
<li><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_xlsx" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.create_xlsx">create_xlsx</a></code></li>
<li><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.get_person_codes" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.get_person_codes">get_person_codes</a></code></li>
<li><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.hist_of_activity_labels" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.hist_of_activity_labels">hist_of_activity_labels</a></code></li>
<li><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.save_summary_to_json" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.save_summary_to_json">save_summary_to_json</a></code></li>
<li><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.standardize_activity_labels" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.standardize_activity_labels">standardize_activity_labels</a></code></li>
<li><code><a title="aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.standardize_videos" href="#aqua.data_tools.aolme.activity_labels.activity_labels_new.AOLMEActivityLabels.standardize_videos">standardize_videos</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>